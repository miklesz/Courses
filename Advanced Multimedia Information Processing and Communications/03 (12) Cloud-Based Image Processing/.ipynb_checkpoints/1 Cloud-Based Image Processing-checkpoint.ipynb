{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```sh\n",
    "jupyter_mac.command\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cloud-Based Image Processing\n",
    "\n",
    "_Mikołaj Leszczuk, Szymon Turek, Jakub Nawała_\n",
    "\n",
    "![](https://i.creativecommons.org/l/by/4.0/88x31.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Image Processing (Computer Vision)\n",
    "\n",
    "![](https://pbs.twimg.com/media/DdPTh-zXcAA1QfM.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cloud Computing\n",
    "\n",
    "![By Sam Johnston - Created by Sam Johnston using OmniGroup's OmniGraffle and Inkscape (includes Computer.svg by Sasa Stefanovic)This vector image was created with Inkscape., CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=6080417\n",
    "![image.png](attachment:image.png)](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Cloud_computing.svg/848px-Cloud_computing.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cloud-Based Image Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Amazon Rekognition**\n",
    "* **Microsoft Azure Computer Vision API**\n",
    "* **Google Cloud API**\n",
    "* **IBM Watson Visual Recognition**\n",
    "* CloudSight AI\n",
    "* Clarifai Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparison of Possibilities Offered by the Above Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Source: https://www.altexsoft.com/blog/datascience/comparing-machine-learning-as-a-service-amazon-microsoft-azure-google-cloud-ai/\n",
    "![image.png](attachment:image.png)](https://content.altexsoft.com/media/2017/03/word-image-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CloudSight AI\n",
    "\n",
    "![](https://avatars.githubusercontent.com/u/5758856)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Generating natural language description based on image content\n",
    "* Recognizing fine-grained objects\n",
    "* Classification of images\n",
    "* Scene understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clarifai\n",
    "\n",
    "![](https://pbs.twimg.com/profile_images/1286339140502654977/FmPAcETU_400x400.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Chosen for exercise\n",
    "* Very simple authentication\n",
    "* Creation of free account not requiring credit card number (notorious procedure for other applications)\n",
    "* Free version of Clarifai allowing to process transactions:\n",
    "  * 5000 images per month if confirmed e-mail\n",
    "  * 100 images per month if unconfirmed e-mail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Clarifai API offering image and video recognition as service\n",
    "* Using AI to recognize visual content\n",
    "* API built around simple idea:\n",
    "  * Sending inputs (image or video) to service\n",
    "  * Receiving predictions\n",
    "  \n",
    "![](https://i0.wp.com/d2dybsqaihwlah.cloudfront.net/wp-content/uploads/2017/05/01211327/inputs-outputs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predict Images via URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* To get predictions for input, need to supply: image and model to get predictions from\n",
    "* Image supply either with publicly accessible URL or by directly sending bytes\n",
    "* Sending up to 128 images in one API call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to Clarifai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The aim of this exercise is to get acquainted with the basics of programming using cloud-based image processing software. The exercise will be performed in the Python programming environment. Utilizing it, we will call remote Clarifai (cloud-based image processing software) functions.\n",
    "\n",
    "![Clarifai Web Logo](https://upload.wikimedia.org/wikipedia/commons/b/bc/Clarifai_Logo_FC_Web.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Below are instructions for setting up an environment for computer vision applications (Python + image processing libraries).\n",
    "\n",
    "**Python** is a general-purpose high-level programming language with an extensive standard library package, whose guiding principle is the readability and clarity of the source code. Its syntax is characterized by transparency and brevity. \n",
    "\n",
    "**Clarifai** is an Artificial Intelligence (AI) cloud service that specializes in computer vision and uses machine learning and deep neural networks to identify and analyze images and videos. The cloud service offers its solutions via API, mobile SDK, and on-premises solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### App-Specific API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "App-specific API Keys are used to authorize your Clarifai applications. A key is automatically generated when you create a new application. You can also go to the application's list, select an app of your choice and create a new key in the app details page. _Each API key is tied to a specific user and a specific app._\n",
    "\n",
    "After creating a free account, the next steps are: (i) create a new application and (ii) generate the application key (the key should be put in the script)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create an Application and Generate the Application Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To create an application, head on over to the applications page and press the 'Create Application' button."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://gblobscdn.gitbook.com/assets%2F-LisemUaXxC3S7Kk9xFz%2Fsync%2F069fd59ae3fb51f51b3acbed9dd72e997287a0f2.png?alt=media)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Start by creating a free Clarifai account ([https://portal.clarifai.com/signup](https://portal.clarifai.com/signup)).\n",
    "\n",
    "[`key.txt`](key.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### API Client Installation Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using client library to access API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Tip 1**: Please note that if you use Python, there might be two independently configured versions installed on the machine: Python 2 (`python`) and Python 3 (`python3`). The two versions are not always compatible. You are advised to use Python 3 as Python 2 support officially ended in January 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Tip 2**: To install Clarifai for Python, you must execute the following _pip_ command (usually you do not need administrative privileges to run this command, please keep in mind that the _pip_ command installs packages only for Python 3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: clarifai-grpc in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (8.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.53.0 in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (from clarifai-grpc) (1.56.0)\n",
      "Requirement already satisfied: requests>=2.25.1 in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (from clarifai-grpc) (2.27.1)\n",
      "Requirement already satisfied: grpcio>=1.36.0 in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (from clarifai-grpc) (1.44.0)\n",
      "Requirement already satisfied: protobuf>=3.15.6 in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (from clarifai-grpc) (3.20.0)\n",
      "Requirement already satisfied: six>=1.5.2 in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (from grpcio>=1.36.0->clarifai-grpc) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.25.1->clarifai-grpc) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.25.1->clarifai-grpc) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.25.1->clarifai-grpc) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.25.1->clarifai-grpc) (2021.10.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install clarifai-grpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Tip 3**: In case of error messages saying that the pip version is too old, you must upgrade it by executing the following command (it can be noted that this should not be necessary and may break your machine configuration):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (22.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Tip 4**: In case of error messages saying that you do not have sufficient permissions, you can use the root (administrator) account. **Before you do so, please first consult with the tutor.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Tip 5**: **If you get the following error when installing the library: ``Failed building wheel for grpcio``**\n",
    "\n",
    "Try upgrading **setuptools** to a version **40.7.1** or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (65.2.0)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-65.3.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.2.0\n",
      "    Uninstalling setuptools-65.2.0:\n",
      "      Successfully uninstalled setuptools-65.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "anaconda-project 0.10.2 requires ruamel-yaml, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.22.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed setuptools-65.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade setuptools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example - Tags Extraction on Images via URL (Prediction of Concepts in an Image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Construct the `V2Stub` object using which you'll access all the Clarifai API functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\n",
    "from clarifai_grpc.grpc.api import service_pb2_grpc\n",
    "\n",
    "stub = service_pb2_grpc.V2Stub(ClarifaiChannel.get_grpc_channel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Predict concepts in an image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://samples.clarifai.com/metro-north.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from clarifai_grpc.grpc.api import service_pb2, resources_pb2\n",
    "from clarifai_grpc.grpc.api.status import status_code_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is how you authenticate. This will be used by every Clarifai endpoint call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with open('key.txt') as f:\n",
    "    key = f.read()\n",
    "\n",
    "metadata = (('authorization', 'Key '+key),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is the model ID of a publicly available General model. You may use any other public or custom model ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model_id = 'aaa03c23b3724a16a56b629203edc62c'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The script should point the Clarifai API to a URL path to an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "request = service_pb2.PostModelOutputsRequest(\n",
    "    model_id=model_id,\n",
    "    inputs=[\n",
    "        resources_pb2.Input(\n",
    "            data=resources_pb2.Data(\n",
    "                image=resources_pb2.Image(\n",
    "                    url='https://samples.clarifai.com/metro-north.jpg'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "response = stub.PostModelOutputs(request, metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, please print the output data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status {\n",
      "  code: SUCCESS\n",
      "  description: \"Ok\"\n",
      "  req_id: \"b5e1fed24f9356efc121c9f0875b9303\"\n",
      "}\n",
      "outputs {\n",
      "  id: \"03908f351849454fa8d4bc3e535e1c66\"\n",
      "  status {\n",
      "    code: SUCCESS\n",
      "    description: \"Ok\"\n",
      "  }\n",
      "  created_at {\n",
      "    seconds: 1661359401\n",
      "    nanos: 831974151\n",
      "  }\n",
      "  model {\n",
      "    id: \"general-image-recognition\"\n",
      "    name: \"Image Recognition\"\n",
      "    created_at {\n",
      "      seconds: 1457543499\n",
      "      nanos: 608845000\n",
      "    }\n",
      "    app_id: \"main\"\n",
      "    output_info {\n",
      "      output_config {\n",
      "      }\n",
      "      message: \"Show output_info with: GET /models/{model_id}/output_info\"\n",
      "      fields_map {\n",
      "        fields {\n",
      "          key: \"concepts\"\n",
      "          value {\n",
      "            string_value: \"softmax\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    model_version {\n",
      "      id: \"aa7f35c01e0642fda5cf400f543e7c40\"\n",
      "      created_at {\n",
      "        seconds: 1520370624\n",
      "        nanos: 454834000\n",
      "      }\n",
      "      status {\n",
      "        code: MODEL_TRAINED\n",
      "        description: \"Model is trained and ready\"\n",
      "      }\n",
      "      visibility {\n",
      "        gettable: PUBLIC\n",
      "      }\n",
      "      app_id: \"main\"\n",
      "      user_id: \"clarifai\"\n",
      "      metadata {\n",
      "      }\n",
      "    }\n",
      "    user_id: \"clarifai\"\n",
      "    input_info {\n",
      "      fields_map {\n",
      "        fields {\n",
      "          key: \"image\"\n",
      "          value {\n",
      "            string_value: \"images\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    train_info {\n",
      "    }\n",
      "    model_type_id: \"visual-classifier\"\n",
      "    visibility {\n",
      "      gettable: PUBLIC\n",
      "    }\n",
      "    modified_at {\n",
      "      seconds: 1658798085\n",
      "      nanos: 654361000\n",
      "    }\n",
      "    import_info {\n",
      "    }\n",
      "  }\n",
      "  input {\n",
      "    id: \"f867b85bab0943bb8ef3962d13ea664b\"\n",
      "    data {\n",
      "      image {\n",
      "        url: \"https://samples.clarifai.com/metro-north.jpg\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  data {\n",
      "    concepts {\n",
      "      id: \"ai_HLmqFqBf\"\n",
      "      name: \"train\"\n",
      "      value: 0.9996053576469421\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_fvlBqXZR\"\n",
      "      name: \"railway\"\n",
      "      value: 0.9992986917495728\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_SHNDcmJ3\"\n",
      "      name: \"subway system\"\n",
      "      value: 0.9982514977455139\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_6kTjGfF6\"\n",
      "      name: \"station\"\n",
      "      value: 0.9980105757713318\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_RRXLczch\"\n",
      "      name: \"locomotive\"\n",
      "      value: 0.9972571730613708\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_Xxjc3MhT\"\n",
      "      name: \"transportation system\"\n",
      "      value: 0.9969801306724548\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_VRmbGVWh\"\n",
      "      name: \"travel\"\n",
      "      value: 0.988979697227478\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_jlb9q33b\"\n",
      "      name: \"commuter\"\n",
      "      value: 0.9808752536773682\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_2gkfMDsM\"\n",
      "      name: \"platform\"\n",
      "      value: 0.9806439876556396\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_n9vjC1jB\"\n",
      "      name: \"light\"\n",
      "      value: 0.9742040634155273\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_sQQj52KZ\"\n",
      "      name: \"train station\"\n",
      "      value: 0.9687402844429016\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_l4WckcJN\"\n",
      "      name: \"blur\"\n",
      "      value: 0.9672204256057739\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_WBQfVV0p\"\n",
      "      name: \"city\"\n",
      "      value: 0.9614798426628113\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_TZ3C79C6\"\n",
      "      name: \"road\"\n",
      "      value: 0.9613829255104065\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_CpFBRWzD\"\n",
      "      name: \"urban\"\n",
      "      value: 0.9603424072265625\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_tr0MBp64\"\n",
      "      name: \"traffic\"\n",
      "      value: 0.9599347710609436\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_GjVpxXrs\"\n",
      "      name: \"street\"\n",
      "      value: 0.9474142789840698\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_mcSHVRfS\"\n",
      "      name: \"public\"\n",
      "      value: 0.9343124032020569\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_J6d1kV8t\"\n",
      "      name: \"tramway\"\n",
      "      value: 0.9318979382514954\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "    concepts {\n",
      "      id: \"ai_6lhccv44\"\n",
      "      name: \"business\"\n",
      "      value: 0.9294139742851257\n",
      "      app_id: \"main\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As the response is formatted using JSON (JavaScript Object Notation), instead of the regular **`print`**, it is better to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                train: 1.00\n",
      "              railway: 1.00\n",
      "        subway system: 1.00\n",
      "              station: 1.00\n",
      "           locomotive: 1.00\n",
      "transportation system: 1.00\n",
      "               travel: 0.99\n",
      "             commuter: 0.98\n",
      "             platform: 0.98\n",
      "                light: 0.97\n",
      "        train station: 0.97\n",
      "                 blur: 0.97\n",
      "                 city: 0.96\n",
      "                 road: 0.96\n",
      "                urban: 0.96\n",
      "              traffic: 0.96\n",
      "               street: 0.95\n",
      "               public: 0.93\n",
      "              tramway: 0.93\n",
      "             business: 0.93\n"
     ]
    }
   ],
   "source": [
    "for concept in response.outputs[0].data.concepts:\n",
    "    print('%21s: %.2f' % (concept.name, concept.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's compare with the image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train railway subway system station locomotive transportation system travel commuter platform light train station blur city road urban traffic street public tramway business "
     ]
    }
   ],
   "source": [
    "[print(concept.name, end=' ') for concept in response.outputs[0].data.concepts];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![](https://samples.clarifai.com/metro-north.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's try with \"Lenna\"...\n",
    "![](https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "request = service_pb2.PostModelOutputsRequest(\n",
    "    model_id=model_id,\n",
    "    inputs=[\n",
    "        resources_pb2.Input(\n",
    "            data=resources_pb2.Data(\n",
    "                image=resources_pb2.Image(\n",
    "                    url='https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "response = stub.PostModelOutputs(request, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fashion woman veil portrait lid girl model elegant retro sexy people glamour one classic wear vintage summer hair beautiful style "
     ]
    }
   ],
   "source": [
    "[print(concept.name, end=' ') for concept in response.outputs[0].data.concepts];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Error handling..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "request = service_pb2.PostModelOutputsRequest(\n",
    "    model_id=model_id,\n",
    "    inputs=[\n",
    "        resources_pb2.Input(\n",
    "            data=resources_pb2.Data(\n",
    "                image=resources_pb2.Image(url='http://foo.bar')\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "response = stub.PostModelOutputs(request, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an error with your request!\n",
      "\tCode: 30104\n",
      "\tDescription: Input invalid argument\n",
      "\tDetails: Could not lookup host \"foo.bar\".\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Request failed, status code: 10020",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDescription: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(response\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mdescription))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDetails: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(response\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mdetails))\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest failed, status code: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(response\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mcode))\n",
      "\u001b[0;31mException\u001b[0m: Request failed, status code: 10020"
     ]
    }
   ],
   "source": [
    "if response.status.code != status_code_pb2.SUCCESS:\n",
    "    print(\"There was an error with your request!\")\n",
    "    print(\"\\tCode: {}\".format(response.outputs[0].status.code))\n",
    "    print(\"\\tDescription: {}\".format(response.outputs[0].status.description))\n",
    "    print(\"\\tDetails: {}\".format(response.outputs[0].status.details))\n",
    "    raise Exception(\"Request failed, status code: \" + str(response.status.code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Additional References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. “Getting Started Guide | Clarifai Developer” (link to the documentation),\n",
    "[https://www.clarifai.com/developer/guide/](https://www.clarifai.com/developer/guide/)\n",
    "1. “Sign Up | Clarifai Developer” (setting up a free account),\n",
    "[https://clarifai.com/developer/account/signup](https://clarifai.com/developer/account/signup)\n",
    "1. “Applications | Clarifai Developer” (creating a new application),\n",
    "[https://clarifai.com/developer/account/applications](https://clarifai.com/developer/account/applications)\n",
    "1. “API Keys | Clarifai Developer” (generation of the application key),\n",
    "[https://www.clarifai.com/developer/account/keys](https://www.clarifai.com/developer/account/keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
