{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digitization - Advanced Topics in Digital Photography\n",
    "###### Michał Grega, Mikołaj Leszczuk, Jakub Nawała\n",
    "### Purpose \n",
    "Purpose of this laboratory is to present the RAW processing workflow for digital images and the HDR technique.\n",
    "### Prerequisites\n",
    "* Basics of digital photography\n",
    "* Basics of image formats\n",
    "\n",
    "#### RAW Processing\n",
    "##### All photographs are © Michał Grega unless stated otherwise.\n",
    "\n",
    "#### What is RAW and why to use it?\n",
    "RAW is a file format used for storing the information on the image taken by the digital camera. It is not an image format. It contains raw (unprocessed) data stored by the physical sensor (radiometric data). Apart from that, a RAW file may contain additional metadata on:\n",
    "* Make and model of the camera,\n",
    "* Physical properties of the sensor,\n",
    "* Exposure and camera settings,\n",
    "* Lens settings,\n",
    "* A highly compressed .jpg thumbnail of the image.\n",
    "\n",
    "Please note, that the camera sensor is most commonly not a pixel matrix (see Fig. 1). It is a CMOS or a CCD (charge-coupled device) sensor covered by a filter (see Fig. 2). Underneath this filter, there is an array of photosensitive subpixels, which do not have to be even of rectangular shape. Therefore in order to convert the radiometric data to an image detailed information on the sensor geometry must be available for the software algorithm.<br>\n",
    "<img src='HDR/CCD.svg' width=\"350\"/>\n",
    "<center> Fig. 1. Sensor layouts (Wikipedia)</center>\n",
    "<img src='HDR/bayer.png' width=\"350\"/>\n",
    "<center> Fig. 2. Bayer colour filter (do you see anything unexpected?) (Wikipedia)</center>\n",
    "\n",
    "#### How it differs from .jpg or .tiff?\n",
    "A RAW image captured by a camera is an uncompressed and unprocessed raw measurement of light. It is commonly referred to as a digital negative, as it serves a similar purpose as a traditional film negative. A .jpg or .tiff image produced by the camera is that digital negative processed (developed) on the fly by the camera built-in software. The software most typically conducts a set of automated operations:\n",
    "1. develop the raw image (knowing the physical properties of the sensor),\n",
    "* enhance the resulting image (by applying contrast and colour correction and sharpening),\n",
    "* apply additional correction algorithms (e.g. red-eye reduction),\n",
    "* compress the image to the desired format (lossy .jpg or lossless .tiff).\n",
    "\n",
    "#### What are the benefits of RAW shooting?\n",
    "The most profound and important benefit is that a photographer retains full control of the creation, correction and compression processes. All the adjustments can be made by hand and tuned in order to achieve the desired effect.<br> \n",
    "Moreover, RAW files offer much better input for post-processing, as the state-of-the-art sensors store (digitize) the data at 14 bits per colour per pixel. It means that a raw image can hold 214 shades per colour, meaning 242 total colours. A .jpg file typically saves 8 bits per colour, meaning 28 shades per colour resulting in 224 colours. In short, the RAW format offers better colour fidelity **(18 orders of magnitude greater than .jpg)**, much higher dynamic range (High Dynamic Range imaging will be explained further on) and more data for further corrections.<br>\n",
    "What are the drawbacks of RAW shooting?\n",
    "* The visual quality of an unenhanced RAW file is not satisfying as no corrections are applied,\n",
    "* RAW images are of large size,\n",
    "* RAW images require tedious manual development and correction. \n",
    "\n",
    "#### RAW processing workflow\n",
    "`\n",
    "Disclaimer:\n",
    "Photography is an art and thus slips away from scientific definition. Moreover, it is controversial how much post-processing (a.k.a) “photoshopping” is allowed to a professional. Photographic agencies and photographic competitions have strict rules that define what is allowed and what is not.\n",
    "`\n",
    "The RAW processing workflow consists of several steps - all described below. Each photographer usually creates his/her own workflow by adding or removing some of the steps. It is important to sustain the order of the steps, as there is a logic behind them (e.g. sharpening has to be done prior to development).\n",
    "1. **Cropping and straightening** – a selection of a composition of the image\n",
    "<img src='HDR/straight.png'/>\n",
    "<center> Before and after straightening </center>\n",
    "2. **Exposure correction** – done in order to correct for over- or underexposed images. Due to the physical characteristics of the sensor a rule of the thumb is that it is better to shoot under-. rather than, overexposed images as it is easier to compensate for underexposure. The most useful tool is the luminosity histogram. A well-exposed photo covers the whole dynamic range and fills the whole histogram. An under- or overexposed photo shows clipping in (respectively) low or high values.\n",
    "<img src='HDR/hist1.png'/>\n",
    "<center> A histogram of an underexposed image </center>\n",
    "<img src='HDR/hist2.png'/>\n",
    "<center> A histogram of an overexposed image</center>\n",
    "<center>(gray area - total luminosity; red, green and blue curves - luminosity for each RGB channel)</center>\n",
    "<img src='HDR/underexp.png'/>\n",
    "<img src='HDR/overexp.png'/>\n",
    "<center> Before and after exposure correction. Notice the histogram.</center>\n",
    "\n",
    "More advanced software allows for a software-based increase in dynamic range (i.e. the increase in an end-to-end distance between extreme pixel values). Software algorithm detects the under- or overexposed parts of the image and enhances them instead of modifying the whole image.\n",
    "<img src='HDR/exp1.png'/>\n",
    "<img src='HDR/exp2.png'/>\n",
    "<img src='HDR/exp3.png'/>\n",
    "<center> Exposure correction using overall exposure and software HDR. Notice the contrast between foreground and background.</center>\n",
    "\n",
    "3. **Contrast correction** – increases the contrast in an image. Images captured in the RAW format appear to be flat and not vibrant. That is due to the lack of contrast correction. Contrast is the difference between the brightest and darkest pixel in the image. While it is easy to define, there are many algorithms that aim at improving contrast by maintaining the general luminosity and colours of the image. \n",
    "\n",
    "<img src='HDR/contrast1.png'/>\n",
    "<img src='HDR/contrast2.png'/>\n",
    "<center> Contrast correction </center>\n",
    "\n",
    "4. **Colour correction** – shooting an image in given conditions may cause the colours to be distorted. Especially the type of light (sunlight vs artificial) makes the colours unnatural. For example, shooting in artificial incandescent light causes images to be unnaturally warm (due to the high amount of infrared radiation). On the other hand, shooting in full sunlight on high altitudes causes photographs to be unnaturally cool (because of the high amount of UV radiation). It can be compensated for using white balance compensation.\n",
    "\n",
    "<img src='HDR/color1.png'/>\n",
    "<img src='HDR/color2.png'/>\n",
    "<center> White balance compensation – notice the clipping on a histogram in the red channel.</center>\n",
    "\n",
    "5. **Sharpening and detail** – allows to sharpen the image and remove unnecessary artefacts. Among those are spots caused by dirt on the sensor (or lenses) and noise generated by the sensor itself.\n",
    "\n",
    "<img src='HDR/shape.png'/>\n",
    "<center> Sharpening and noise reduction</center>\n",
    "\n",
    "6. **Development** – allows converting the image to the target format and colour space.\n",
    "\n",
    "#### RAW processing exercise\n",
    "1. You can use any RAW processing software you wish. Note, however, that the paid software usually offers a more intuitive interface and more advanced algorithms. If you own a DSLR (Digital Single-Lens Reflex) camera you probably got a copy of the manufacturer’s software. Other (costly) solutions are Adobe Photoshop with Lightroom or Capture One (for the use in the laboratory you have to download a version from https://www.phaseone.com/en/Download.aspx).<br>You can also use (free) http://rawtherapee.com/.<br>Examples shown in the previous section were prepared using Capture One Pro, which offers a free 30-day trial. \n",
    "2. Download example RAW files (see the “RAW Examples” folder accompanying this instruction).\n",
    "3. Develop these RAW files into *.jpg images for web publishing trying to achieve the best visual result. Correct the composition, exposure and colours of the image. Apply sharpening and the correct developmental recipe. Observe what happens when you use high values of the corrections for sharpness, software HDR, exposition. There is a saying for beginners “Set up your sliders in a position that makes your photograph look good and then reduce all by half”.\n",
    "\n",
    "#### HDR Imaging\n",
    "As you might have noticed, one of the most challenging scenes is those with high contrast between shadowy and bright regions. Each optical device, including the human eye, has a dynamic range. A dynamic range is a difference measured in EV units between the darkest and brightest part of the image that shows detail. Increase of one EV unit represents a situation where the amount of light is doubled. A human eye and a modern DSLR camera sensor have a dynamic range of approx. 14 EV (called “stops”). It means that we can double the amount of light 14 times between the brightest and darkest part of the image and still see detail.<br>We can control which part of the scene is covered by our EV range by adjusting the shutter speed, aperture or ISO value of the sensor. We, however, cannot increase this range.\n",
    "\n",
    "#### What is HDR?\n",
    "HDR, High Dynamic Range, is a photographing technique, in which a set of images is made with different camera setups. Each photograph covers a limited dynamic range, but a combination of the photographs covers a higher dynamic range resulting in an HDR photograph.<br>Of course, the display or printout also has a limited dynamic range, thus a mapping from the wider to the narrower dynamic range has to be done. This is referred to as “tone mapping”.<br>For an exemplary usage of the HDR technique, please take a look at the example below.\n",
    "\n",
    "<img src='HDR/hdr_grd.png'/>\n",
    "<center> HDR input images. Note, that it was impossible to get details both on the bright (sky) and dark (shadows) areas in any single photo.</center>\n",
    "<img src='HDR/hdr_grd_out.png'/>\n",
    "<center> HDR result. Notice, that it looks unnatural, as it shows a higher dynamic range than a human eye is able to process.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Dynamic Range (HDR) exercise\n",
    "#### Here you can see how HDR works with examples. In exercise used 3 different HDR methods:\n",
    "#### - Debevec\n",
    "#### - Robertson\n",
    "#### - Martens\n",
    "### Each of them you can check with 3 images taken with different exposure time. \n",
    "### At first please click button below to load settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<button id=\"do_run_all\">Click to run exercise</button>\n",
       "<script>\n",
       "$(\"#do_run_all\").click(\n",
       "    function () {\n",
       "        $(\"#run_all_cells\").click();\n",
       "    }\n",
       ");\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''\n",
    "<button id=\"do_run_all\">Click to run exercise</button>\n",
    "<script>\n",
    "$(\"#do_run_all\").click(\n",
    "    function () {\n",
    "        $(\"#run_all_cells\").click();\n",
    "    }\n",
    ");\n",
    "</script>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here you can see oryginal taken pictures with average time of exposure. Below them, choose from drop-down menu picture you would like to see after HDR conversion.\n",
    "##### Yosemite:\n",
    "![](HDR/yosemite2.png)\n",
    "\n",
    "##### Garden:\n",
    "![](HDR/garden2.png)\n",
    "\n",
    "##### Mount:\n",
    "![](HDR/mount2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Please choose from drop-down menu kind of image and then choose one of 3 HDR method.\n",
    "##### Due to interactive mode of example, please give several seconds to compute the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ext = '.png'\n",
    "file_dir = 'HDR/'\n",
    "\n",
    "def show_oryg(img_1, img_2, img_3):\n",
    "     \n",
    "    pyplot.figure(figsize=[18.0, 12.0])\n",
    "    pyplot.subplot(1,3,1)\n",
    "    pyplot.imshow(img_1)\n",
    "    pyplot.axis('off')\n",
    "    pyplot.subplot(1,3,2)\n",
    "    pyplot.imshow(img_2)\n",
    "    pyplot.axis('off')\n",
    "    pyplot.subplot(1,3,3)\n",
    "    pyplot.imshow(img_3)\n",
    "    pyplot.axis('off')\n",
    "    pyplot.suptitle('Oryginal taken images', x=0.5, y=0.65, fontsize=21)\n",
    "    \n",
    "    \n",
    "def show_hdr(hdr_out, hdr_type):\n",
    "    pyplot.figure(figsize=[9.0, 6.0])\n",
    "    pyplot.title('Image created by {} HDR type.'.format(hdr_type.upper()))\n",
    "    pyplot.imshow(hdr_out)\n",
    "    pyplot.axis('off')\n",
    "    pyplot.show();\n",
    "\n",
    "def load_files(image):\n",
    "    img_fn = [file_dir+image+str(num)+file_ext for num in range(1,4)]\n",
    "    img_list = [cv2.imread(fn) for fn in img_fn]\n",
    "    img_list_ok = [cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for img in img_list]\n",
    "    return img_list_ok;\n",
    "    \n",
    "def hdr(image, hdr_type):\n",
    "    img_list_ok = load_files(image)\n",
    "    img_1, img_2, img_3 = img_list_ok\n",
    "    show_oryg(img_1, img_2, img_3)\n",
    "    exposure_times = np.array([50.0, 11.0, 3.0],dtype=np.float32) #, dtype=np.float32\n",
    "    tonemap1 = cv2.createTonemap(gamma=2.2)\n",
    "    \n",
    "    if hdr_type == 'robertson':\n",
    "        merge_robertson = cv2.createMergeRobertson()\n",
    "        hdr_robertson = merge_robertson.process(img_list_ok, times=exposure_times.copy())\n",
    "        res_robertson = tonemap1.process(hdr_robertson.copy())\n",
    "        hdr_out = np.clip(res_robertson*255, 0, 255).astype('uint8')\n",
    "        \n",
    "\n",
    "    elif hdr_type == 'mertens':\n",
    "        merge_mertens = cv2.createMergeMertens()\n",
    "        res_mertens = merge_mertens.process(img_list_ok)\n",
    "        hdr_out = np.clip(res_mertens*255, 0, 255).astype('uint8')\n",
    "        \n",
    "    elif hdr_type == 'debevec':\n",
    "        time = exposure_times\n",
    "        merge_debevec = cv2.createMergeDebevec()\n",
    "        hdr_debevec = merge_debevec.process(img_list_ok, times=time.copy())\n",
    "        res_debevec = tonemap1.process(hdr_debevec.copy())\n",
    "        hdr_out = np.clip(res_debevec*255, 0, 255).astype('uint8')\n",
    "    \n",
    "    else:\n",
    "        print('Błąd funkcji \"hdr\".')\n",
    "        \n",
    "    show_hdr(hdr_out, hdr_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfd829f8fde46e882e7f5e4a65dea6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image', options=('yosemite', 'garden', 'mount'), value='yosemite')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(hdr, image=['yosemite','garden','mount'], hdr_type=['robertson','mertens','debevec']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What the profit is using HDR conversion?\n",
    "#### Is there important difference with types of HDR conversion? If so, which of them is the best for examples above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ###### Exercise have been written using Python3 programming language. Click the button below only in case you would like to see code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Show/Hide source code\"></form>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''\n",
    "<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Show/Hide source code\"></form>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
