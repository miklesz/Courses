{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa64895",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Shot Boundary Detection (SBD) - Exercises\n",
    "\n",
    "_Authors: Mikołaj Leszczuk_\n",
    "\n",
    "[http://qoe.agh.edu.pl](http://qoe.agh.edu.pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce5c565",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Purpose of the Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6e6b3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The purpose of this exercise is acquiring the practice in opportunities for video content analysis. An example of video content analysis is automatic Shot Boundary Detection (SBD). SBD is commonly used in case of creating video summarizations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db9778c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Needed Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5692dd9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Before starting exercise, one should possess knowledge in the following topics: \n",
    "* SBD basics (why it is used) \n",
    "* SBD methods (general information) \n",
    "* Applications for SBD used during the exercise "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff823313",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Work Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e52dba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We will use the following solution for SBD: [PySceneDetect](http://scenedetect.com/en/latest/) ([the PySceneDetect Python API (the *scenedetect* module)](https://scenedetect.com/projects/Manual/en/latest/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81867679",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (22.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pip --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e1d76a2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scenedetect in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (0.6.0.3)\n",
      "Collecting scenedetect\n",
      "  Using cached scenedetect-0.6.1-py3-none-any.whl (115 kB)\n",
      "Requirement already satisfied: Click in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (from scenedetect) (8.0.4)\n",
      "Requirement already satisfied: appdirs in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (from scenedetect) (1.4.4)\n",
      "Requirement already satisfied: numpy in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (from scenedetect) (1.22.4)\n",
      "Requirement already satisfied: tqdm in /Users/miklesz/opt/anaconda3/lib/python3.9/site-packages (from scenedetect) (4.64.0)\n",
      "Installing collected packages: scenedetect\n",
      "  Attempting uninstall: scenedetect\n",
      "    Found existing installation: scenedetect 0.6.0.3\n",
      "    Uninstalling scenedetect-0.6.0.3:\n",
      "      Successfully uninstalled scenedetect-0.6.0.3\n",
      "Successfully installed scenedetect-0.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scenedetect --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aa4217",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Execution of the Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292be10a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The first task is the preparation of a video, which will be used for testing SBD systems. You may use files with videos (like: [UGS05.mpg](UGS05.mpg)); alternatively, it is possible to find video files (having numerous, easy to distinguish, shots) on the Internet. The proposes files are preferred as they are accompanied by manually created reference shot positions (`ref_*.csv` files, column: `manual_past_f_num`). Please be aware that not all video formats and codecs are handled by the programs used for the exercise. The videos should not be too long as the exercise duration is limited. In the case of long videos, it is acceptable to analyze only a part of a video. The audio track is not used; thus, also it is not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6115d54",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If the reference shot positions are not available, you should oversee the video to obtain real shot boundaries. Please note that different programs may use numbering of frame numbers starting from `0` or `1`, in case of incompatibility, you should apply the appropriate translation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e96a5c2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The next steps are a try of automatic SBD in the video, and then, a determination of the accuracy of SBD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70467dd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To get started, the **`scenedetect.detect()`** function takes a path to a video and a [scene detector object](https://scenedetect.com/projects/Manual/en/latest/api/detectors.html#scenedetect-detectors), and returns a list of start/end timecodes. For detecting fast cuts (shot changes), we use the **`ContentDetector`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eecf9e3d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected: 24 | Progress: 100%|███████| 40098/40098 [01:04<00:00, 621.57frames/s]\n"
     ]
    }
   ],
   "source": [
    "from scenedetect import detect, ContentDetector\n",
    "shot_list = detect(\n",
    "    video_path='UGS05.mpg',\n",
    "    detector=ContentDetector(),\n",
    "    stats_file_path='stats_file.txt',\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc6ecb6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that when calling **`detect`** we set `stats_file_path='stats_file.txt'` save per-frame metrics to [stats_file.txt](stats_file.txt) and we set `show_progress=True` to display a progress bar with estimated time remaining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d1679",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`shot_list` is now a list of **`FrameTimecode`** pairs representing the start/end of each shot (try printing `shot_list`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09f841dc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(00:00:00.000 [frame=0, fps=29.970], 00:00:02.002 [frame=60, fps=29.970]),\n",
       " (00:00:02.002 [frame=60, fps=29.970], 00:00:26.026 [frame=780, fps=29.970]),\n",
       " (00:00:26.026 [frame=780, fps=29.970], 00:00:46.246 [frame=1386, fps=29.970]),\n",
       " (00:00:46.246 [frame=1386, fps=29.970],\n",
       "  00:00:55.455 [frame=1662, fps=29.970]),\n",
       " (00:00:55.455 [frame=1662, fps=29.970],\n",
       "  00:01:04.698 [frame=1939, fps=29.970]),\n",
       " (00:01:04.698 [frame=1939, fps=29.970],\n",
       "  00:01:12.906 [frame=2185, fps=29.970]),\n",
       " (00:01:12.906 [frame=2185, fps=29.970],\n",
       "  00:01:22.115 [frame=2461, fps=29.970]),\n",
       " (00:01:22.115 [frame=2461, fps=29.970],\n",
       "  00:02:17.471 [frame=4120, fps=29.970]),\n",
       " (00:02:17.471 [frame=4120, fps=29.970],\n",
       "  00:07:13.733 [frame=12999, fps=29.970]),\n",
       " (00:07:13.733 [frame=12999, fps=29.970],\n",
       "  00:07:31.918 [frame=13544, fps=29.970]),\n",
       " (00:07:31.918 [frame=13544, fps=29.970],\n",
       "  00:07:52.439 [frame=14159, fps=29.970]),\n",
       " (00:07:52.439 [frame=14159, fps=29.970],\n",
       "  00:09:12.252 [frame=16551, fps=29.970]),\n",
       " (00:09:12.252 [frame=16551, fps=29.970],\n",
       "  00:11:00.527 [frame=19796, fps=29.970]),\n",
       " (00:11:00.527 [frame=19796, fps=29.970],\n",
       "  00:11:40.633 [frame=20998, fps=29.970]),\n",
       " (00:11:40.633 [frame=20998, fps=29.970],\n",
       "  00:12:16.703 [frame=22079, fps=29.970]),\n",
       " (00:12:16.703 [frame=22079, fps=29.970],\n",
       "  00:13:55.702 [frame=25046, fps=29.970]),\n",
       " (00:13:55.702 [frame=25046, fps=29.970],\n",
       "  00:14:14.787 [frame=25618, fps=29.970]),\n",
       " (00:14:14.787 [frame=25618, fps=29.970],\n",
       "  00:17:12.899 [frame=30956, fps=29.970]),\n",
       " (00:17:12.899 [frame=30956, fps=29.970],\n",
       "  00:19:12.551 [frame=34542, fps=29.970]),\n",
       " (00:19:12.551 [frame=34542, fps=29.970],\n",
       "  00:19:27.800 [frame=34999, fps=29.970]),\n",
       " (00:19:27.800 [frame=34999, fps=29.970],\n",
       "  00:19:38.010 [frame=35305, fps=29.970]),\n",
       " (00:19:38.010 [frame=35305, fps=29.970],\n",
       "  00:19:48.220 [frame=35611, fps=29.970]),\n",
       " (00:19:48.220 [frame=35611, fps=29.970],\n",
       "  00:20:00.299 [frame=35973, fps=29.970]),\n",
       " (00:20:00.299 [frame=35973, fps=29.970],\n",
       "  00:22:16.602 [frame=40058, fps=29.970]),\n",
       " (00:22:16.602 [frame=40058, fps=29.970],\n",
       "  00:22:17.903 [frame=40097, fps=29.970])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shot_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ecf6d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next, let’s print the shot list in a more readable format by iterating over it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78a6758b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shot  1: Start 00:00:00.000 / Frame 0, End 00:00:02.002 / Frame 60\n",
      "Shot  2: Start 00:00:02.002 / Frame 60, End 00:00:26.026 / Frame 780\n",
      "Shot  3: Start 00:00:26.026 / Frame 780, End 00:00:46.246 / Frame 1386\n",
      "Shot  4: Start 00:00:46.246 / Frame 1386, End 00:00:55.455 / Frame 1662\n",
      "Shot  5: Start 00:00:55.455 / Frame 1662, End 00:01:04.698 / Frame 1939\n",
      "Shot  6: Start 00:01:04.698 / Frame 1939, End 00:01:12.906 / Frame 2185\n",
      "Shot  7: Start 00:01:12.906 / Frame 2185, End 00:01:22.115 / Frame 2461\n",
      "Shot  8: Start 00:01:22.115 / Frame 2461, End 00:02:17.471 / Frame 4120\n",
      "Shot  9: Start 00:02:17.471 / Frame 4120, End 00:07:13.733 / Frame 12999\n",
      "Shot 10: Start 00:07:13.733 / Frame 12999, End 00:07:31.918 / Frame 13544\n",
      "Shot 11: Start 00:07:31.918 / Frame 13544, End 00:07:52.439 / Frame 14159\n",
      "Shot 12: Start 00:07:52.439 / Frame 14159, End 00:09:12.252 / Frame 16551\n",
      "Shot 13: Start 00:09:12.252 / Frame 16551, End 00:11:00.527 / Frame 19796\n",
      "Shot 14: Start 00:11:00.527 / Frame 19796, End 00:11:40.633 / Frame 20998\n",
      "Shot 15: Start 00:11:40.633 / Frame 20998, End 00:12:16.703 / Frame 22079\n",
      "Shot 16: Start 00:12:16.703 / Frame 22079, End 00:13:55.702 / Frame 25046\n",
      "Shot 17: Start 00:13:55.702 / Frame 25046, End 00:14:14.787 / Frame 25618\n",
      "Shot 18: Start 00:14:14.787 / Frame 25618, End 00:17:12.899 / Frame 30956\n",
      "Shot 19: Start 00:17:12.899 / Frame 30956, End 00:19:12.551 / Frame 34542\n",
      "Shot 20: Start 00:19:12.551 / Frame 34542, End 00:19:27.800 / Frame 34999\n",
      "Shot 21: Start 00:19:27.800 / Frame 34999, End 00:19:38.010 / Frame 35305\n",
      "Shot 22: Start 00:19:38.010 / Frame 35305, End 00:19:48.220 / Frame 35611\n",
      "Shot 23: Start 00:19:48.220 / Frame 35611, End 00:20:00.299 / Frame 35973\n",
      "Shot 24: Start 00:20:00.299 / Frame 35973, End 00:22:16.602 / Frame 40058\n",
      "Shot 25: Start 00:22:16.602 / Frame 40058, End 00:22:17.903 / Frame 40097\n"
     ]
    }
   ],
   "source": [
    "for i, shot in enumerate(shot_list):\n",
    "    print('Shot %2d: Start %s / Frame %d, End %s / Frame %d' % (\n",
    "        i+1,\n",
    "        shot[0].get_timecode(), shot[0].get_frames(),\n",
    "        shot[1].get_timecode(), shot[1].get_frames(),))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e6c739",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f159ec8e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let us use methods presented in the lecture for determining the accuracy of SBD (in particular, let us try to assess the accuracy of SBD using Precision and Recall metrics). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d13550e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60, 780, 1386, 1662, 1939, 2185, 2461, 4120, 12999, 13544, 14159, 16551, 19796, 20998, 22079, 25046, 25618, 30956, 34542, 34999, 35305, 35611, 35973, 40058, 40097]\n"
     ]
    }
   ],
   "source": [
    "positives = [shot[1].get_frames() for shot in shot_list]\n",
    "print(positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8f90664",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60, 780, 1386, 1662, 1939, 2185, 2461, 4120, 12999, 13544, 14159, 16551, 19796, 20998, 22079, 23041, 24163, 25046, 27080, 29383, 30956, 31320, 34542, 34999, 35305, 35611, 35973, 36575, 36877, 37959, 38861, 40058]\n"
     ]
    }
   ],
   "source": [
    "with open('ref_UGS05.csv') as file_object:\n",
    "    ground_truth = [int(line) for line in file_object.readlines()[1:]]\n",
    "print(ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a90f91",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Obtaining lists of true positives and false positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5459b4bd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "true_positives = []\n",
    "false_positives = []\n",
    "for positive in positives:\n",
    "    if positive in ground_truth:\n",
    "        true_positives.append(positive)\n",
    "    else:\n",
    "        false_positives.append(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "222816b8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60, 780, 1386, 1662, 1939, 2185, 2461, 4120, 12999, 13544, 14159, 16551, 19796, 20998, 22079, 25046, 30956, 34542, 34999, 35305, 35611, 35973, 40058]\n"
     ]
    }
   ],
   "source": [
    "print(true_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41a584b3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25618, 40097]\n"
     ]
    }
   ],
   "source": [
    "print(false_positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b512a3a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Obtaining values of $t_p$ and $f_p$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "179c6f25",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "tp = len(true_positives)\n",
    "print(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cad24eb4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "fp = len(false_positives)\n",
    "print(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f51b67",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Obtaining list of false negatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32feddb8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23041, 24163, 27080, 29383, 31320, 36575, 36877, 37959, 38861]\n"
     ]
    }
   ],
   "source": [
    "false_negatives = [\n",
    "    false_negative for false_negative in ground_truth if false_negative not in positives\n",
    "]\n",
    "print(false_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f380d9c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Obtaining value of $f_n$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1e2fafe",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "fn = len(false_negatives)\n",
    "print(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44025ae4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ontaining value of $t_n$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fae3e0e2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40064\n"
     ]
    }
   ],
   "source": [
    "with open('stats_file.txt') as file_object:\n",
    "    tn = len(file_object.readlines()) - tp - fp - fn\n",
    "print(tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e789bd1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Obtaining values of Precision, Recall and Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "857e381d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n"
     ]
    }
   ],
   "source": [
    "p = tp / (tp + fp)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92486567",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71875\n"
     ]
    }
   ],
   "source": [
    "r = tp / (tp + fn)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "472b0b94",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9997256721033468\n"
     ]
    }
   ],
   "source": [
    "a = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19433898",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If time permits, after testing SBD for video content with easily detectable shot boundaries, please try downloading the video (or videos) where shot boundaries are not so visible. Please do the tests for these videos as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893ca96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06d8dc6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In a report (if required – please check) please consider methods presented in the lecture for determining the accuracy of SBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64b23cc",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
