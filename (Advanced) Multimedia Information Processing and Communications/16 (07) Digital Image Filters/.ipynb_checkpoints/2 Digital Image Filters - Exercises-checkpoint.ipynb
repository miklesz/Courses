{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e07295b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Digital Image Filters (in Practice)\n",
    "\n",
    "## Introduction to Image Processing Using Python\n",
    "\n",
    "_Authors: Mikołaj Leszczuk, Zbigniew Hulicki, Jakub Nawała_\n",
    "\n",
    "[http://qoe.agh.edu.pl](http://qoe.agh.edu.pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cdd990",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Theoretical Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e9513",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Digital filters are a central part of many signal processing systems. Image filtering is a mathematical operation on pixels of the source image, which results in a new, transformed image being produced. Its primary usage is to extract properties of the input image. Those are usually used in further processing steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefbbabc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can perform filtration in a spatial domain or the frequency domain. In the first case, a convolution operation between a matrix (called “kernel”) and the input image is applied (for the sake of correctness, we are using a discrete convolution, where both operands have a finite number of points). In the second case, a frequency domain representation of the input image is multiplied with a given filter characteristic. The filtering effect depends on the size and type of filter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45307fe2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can distinguish two (2) general types of frequency domain filters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec053d25",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. A low-pass filter – used for the removal of picture elements being a part of high-frequency spatial features (such as large colour differences between adjacent pixels), while leaving low-frequency features (e.g. large shapes without details) intact. Most of the noise present in images is contained in spatial characteristics of high frequency. Thus, such a low-pass filter may be used to compensate for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff308a5d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. A high-pass filter – acts in a manner opposite to the low pass filter. It attenuates low-frequency features while reinforcing high-frequency ones. This behaviour highlights picture elements of high spatial frequency by increasing their visibility (e.g. brightness or colour). In practice, this corresponds to the emphasis of sharp edges of objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7327056",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If it comes to spatial domain filters, those may be divided into linear and nonlinear. For linear filters, a kernel defines a type. By choosing the size and values of its cells, we may achieve various effects. For example, one can smooth (see figure showing an exemplary kernel of the mean filter - also called smoothing filter) or sharpen the image. In some more advanced cases, it is also possible to find edges and other more sophisticated features.\n",
    "\n",
    "| | | |\n",
    "| -- | -- | -- |\n",
    "| $$\\frac{1}{9}$$ | $$\\frac{1}{9}$$ | $$\\frac{1}{9}$$ |\n",
    "| $$\\frac{1}{9}$$ | $$\\frac{1}{9}$$ | $$\\frac{1}{9}$$ |\n",
    "| $$\\frac{1}{9}$$ | $$\\frac{1}{9}$$ | $$\\frac{1}{9}$$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5511b16c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "During the exercises, we are going to test a couple of filters. The following modules: `numpy`, `cv2`, `matplotlib.pyplot` and `skimage` of Python are used for this purpose. To ensure it is properly installed, please enter `pip list` (or `pip3 list`) in the command line. It displays an alphabetical list of installed modules, followed by information about the version. Search through the list and find `numpy`, `cv2`, `matplotlib.pyplot` and `skimage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdcc908",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64971381",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For a documentation of the modules, enter `help(<module>)`. To get more specific information about the syntax and exemplary usage, type `help(<module>.<function_name>)` (replace `<module>` and `<function_name>` with a name of the module and the function you want to check)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc08a90",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# help(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888a85b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "# help(cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef59a6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# help(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9626b2f3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "# help(skimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510a96a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The List of Selected Useful Functions and Their Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aa484d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| | |\n",
    "| :- | :- |\n",
    "| `a = cv2.imread(filename)`                     | It loads an image to the `a` array. |\n",
    "| `plt.imshow(a) `                               | It displays an image from the `a` array. |\n",
    "| `(lines, columns, channels) = a.shape`         | It shows the size of the image `m` (number of `lines`, `columns`, `channels`). |\n",
    "| `skimage.img_as_ubyte(a1)`                     | It changes the type of a numerical array to `uint8` (8-bit unsigned integer). |\n",
    "| `a1 = skimage.util.random_noise(a, mode=type)` | It adds noise of a given type to the intensity (meaning single channel) image `a`. Type can take a value from a predefined list. One important example is `s&p` (“salt & pepper”). |\n",
    "| `b = skimage.filters.rank.median(a)`           | It performs median filtering of the `a` matrix along both dimensions (horizontal and vertical). |\n",
    "| `plt.title('your title')`                      | It adds the `your title` title to the plot. |\n",
    "| `b = cv2.filter2D(a, -1, kernel)`              | It returns a filtered version of the grayscale or „true colour” (meaning RGB) input image `a`. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d59e9e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Digital Filters in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f119a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sharpen Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f26f88e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now is the time to load the first image and do some actions on it. Please take a look at an exemplary source code below fetching a `meadow.png` image and running the unsharp filter for a reference on how to load the image.\n",
    "\n",
    "As can be seen, the first filter to be tested is the sharpen filter.\n",
    "\n",
    "Run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418103a7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Loading image and using sharpen filter\n",
    "a = cv2.imread('Images/meadow.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c7f2d8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kernel = np.array(\n",
    "    [\n",
    "        [-1,-1,-1],\n",
    "        [-1, 9,-1], \n",
    "        [-1,-1,-1]\n",
    "    ]\n",
    ")\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2a2747",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.sum(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd010a3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "b = cv2.filter2D(a, -1, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994efa36",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Your script should show that filtering enhanced the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48de3d6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(a, cv2.COLOR_BGR2RGB));\n",
    "plt.title('original');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a1a4af",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(b, cv2.COLOR_BGR2RGB));\n",
    "plt.title('sharpen');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65df40f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice that some image features, such as edges, look sharper. Do you see any artefacts appearing as well? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3360be06",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What happens if we apply this filter many times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7182016",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "c = cv2.filter2D(b, -1, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9893962",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(b, cv2.COLOR_BGR2RGB));\n",
    "plt.title('sharpen');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f64bd5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(c, cv2.COLOR_BGR2RGB));\n",
    "plt.title('sharpen 2 times');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593ad30",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let us rerun the script, but this time use the `car.png` image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67322dc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a = cv2.imread('Images/car.png')\n",
    "b = cv2.filter2D(a, -1, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c29b08",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(a, cv2.COLOR_BGR2RGB));\n",
    "plt.title('original');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe19c2f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(b, cv2.COLOR_BGR2RGB));\n",
    "plt.title('sharpen');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea3730f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let us do the same with the `black.png` image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff099f1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a = cv2.imread('Images/black.png')\n",
    "b = cv2.filter2D(a, -1, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6138e806",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(a, cv2.COLOR_BGR2RGB));\n",
    "plt.title('original');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673d042a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(b, cv2.COLOR_BGR2RGB));\n",
    "plt.title('sharpen');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d4e3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Image Blurring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6283d9a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Blurring image using normalized box filter (destination image is of same size & type as source image)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e8dbd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "cv2.blur(image, ksize[, dst[, anchor[, borderType]]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2999c71",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Arguments**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b317b09f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* `image` – input image; having any channels number processed independently\n",
    "* `ksize` – blurring kernel size\n",
    "* `anchor` – anchor point; default value `Point(-1,-1)` meaning anchor at kernel centre\n",
    "* `borderType` – border mode used to extrapolate pixels outside of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e456ed9",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('Images/meadow.png')\n",
    "blur = cv2.blur(image, (10, 10))\n",
    "plt.imshow(cv2.cvtColor(blur, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aa936b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Disk Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba078ca",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The second filter to evaluate is the disk filter. It is used to blur images. In practice, it applies the circular averaging filter. Please take a look at an exemplary source code fetching an image and running the disk filter with two radii (1 and 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a5f640",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Loading image and using radius filter\n",
    "a = cv2.imread('Images/meadow.png')\n",
    "radius = 1\n",
    "a1 = skimage.morphology.disk(radius)\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a46b5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.sum(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9facbe3b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a1 = skimage.morphology.disk(radius) / np.sum(skimage.morphology.disk(radius))\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb5d14c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.sum(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b726018",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a2 = cv2.filter2D(a, -1, a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c940f",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "radius = 10\n",
    "a10 = skimage.morphology.disk(radius)\n",
    "a10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8422a4bf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a10 = skimage.morphology.disk(radius) / np.sum(skimage.morphology.disk(radius))\n",
    "a20 = cv2.filter2D(a, -1, a10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540df5f6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(a, cv2.COLOR_BGR2RGB));\n",
    "plt.title('original');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ae8d0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(a2, cv2.COLOR_BGR2RGB));\n",
    "plt.title('radius = 1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822c8f16",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(a, cv2.COLOR_BGR2RGB));\n",
    "plt.title('original');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b01380",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(a20, cv2.COLOR_BGR2RGB));\n",
    "plt.title('radius = 10');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97196a2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How does the radius of the filter influence the operation? Let us try to apply the filter with the smaller radius several times and compare it with a single run of the larger radius filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066b237",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a2x10 = a\n",
    "for i in range(10):\n",
    "    a2x10 = cv2.filter2D(a2x10, -1, a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6e694a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(a2x10, cv2.COLOR_BGR2RGB));\n",
    "plt.title('radius = 1 x 10');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ab7f9d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(a20, cv2.COLOR_BGR2RGB));\n",
    "plt.title('radius = 10');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9d2fc6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Guided Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d554766",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A guided filter is an edge-preserving smoothing image filter.\n",
    "* It can filter out noise or texture while retaining sharp edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aebc70",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Applying bilateral filter to image (destination image is of same size & type as source image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ff251a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pip install --upgrade opencv-python opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b0c09",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a36046d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "cv2.ximgproc.guidedFilter(guide, src, radius, eps[, dst[, dDepth]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fba9c2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Arguments**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c1fdcd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* `guide` – guided image (or array of images) with up to 3 channels, if it have more then 3 channels then only first 3 channels will be used.\n",
    "* `src` – filtering image with any numbers of channels.\n",
    "* `dst` – output image.\n",
    "* `radius` – radius of Guided Filter.\n",
    "* `eps` – regularization term of Guided Filter; larger parameter value meaning farther colours within pixel neighbourhood mixed together, resulting in larger areas of semi-equal colour.\n",
    "* `dDepth` – optional depth of the output image.\n",
    "\n",
    "For more details about Guided Filter parameters, see the original article: Kaiming He, Jian Sun, and Xiaoou Tang. Guided image filtering. In *Computer Vision–ECCV 2010*, pages 1–14. Springer, 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f2cefc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"Images/meadow.png\")\n",
    "guided = cv2.ximgproc.guidedFilter(image, image, 5, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62069373",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceacb8f3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(guided, cv2.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ca3f80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Non-Linear Digital Filters in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ee4c58",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bilateral Image Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4639ad93",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A **bilateral filter** is a non-linear, edge-preserving, and noise-reducing smoothing filter for images.\n",
    "* As with a guided filter, it can filter out noise or texture while retaining sharp edges.\n",
    "* It replaces the intensity of each pixel with a weighted average of intensity values from nearby pixels.\n",
    "* This weight can be based on a Gaussian distribution.\n",
    "* Crucially, the weights depend not only on Euclidean distance of pixels, but also on the radiometric differences (e.g., range differences, such as color intensity, depth distance, etc.).\n",
    "* This preserves sharp edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d044c3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Applying bilateral filter to image (destination image is of same size & type as source image)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fef98a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "cv2.bilateralFilter(image, d, sigmaColor, sigmaSpace[, dst[, borderType]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ac073a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Arguments**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b249d8fb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* `image` – source 8-bit or floating-point, 1-channel or 3-channel image\n",
    "* `d` – diameter of each pixel neighbourhood used during filtering; computed from `sigmaSpace` if non-positive\n",
    "* `sigmaColor` – filter sigma in colour space; the sigma in the color space is similar to ${eps}^2$ into guidedFilter.\n",
    "* `sigmaSpace` – filter sigma in coordinate space; larger parameter value meaning farther pixels influencing each other if their colours close enough (see `sigmaColor`); specifying neighbourhood size regardless of `sigmaSpace` when `d>0`; otherwise, `d` proportional to `sigmaSpace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214edcca",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('Images/meadow.png')\n",
    "bilateral = cv2.bilateralFilter(image, 15, 75, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a324a29",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8bd069",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(bilateral, cv2.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33daf662",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparison (Guided Filter vs. Bilateral Filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490fc56",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Compared to the bilateral filter, the guided image filter has two advantages:\n",
    "1. Bilateral filters have high computational complexity, while the guided image filter uses simpler calculations with linear computational complexity.\n",
    "1. Bilateral filters sometimes include unwanted gradient reversal artifacts and cause image distortion. The guided image filter is based on linear combination, making the output image consistent with the gradient direction of the guidance image, preventing gradient reversal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf63fc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(guided, cv2.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0462e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(bilateral, cv2.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5ced1b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Median Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e1264e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The last test is the median filter. Recall that it is efficient in removing “salt-and-pepper” noise without significantly reducing the sharpness of the image. Please refer to an exemplary source code fetching an image, applying the “salt-and-pepper” noise to it and filtering it using the median filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f3716",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Loading image and using noise on image to show how filter works\n",
    "a = cv2.imread('Images/meadow.png')\n",
    "noise = skimage.util.random_noise(a, mode='s&p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab27d1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b762d1",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "noise.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f001e65",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "noise = skimage.img_as_ubyte(skimage.util.random_noise(a, mode='s&p'))\n",
    "noise.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c66868",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# We need to use filter for each channel separately\n",
    "b = skimage.filters.rank.median(noise[:, :, 0])\n",
    "g = skimage.filters.rank.median(noise[:, :, 1])\n",
    "r = skimage.filters.rank.median(noise[:, :, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b239a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# We need to reconstruct the image from separated channels\n",
    "a1 = np.dstack((b, g, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a0d3c0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(a, cv2.COLOR_BGR2RGB));\n",
    "plt.title('original');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c9f9f6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(noise, cv2.COLOR_BGR2RGB));\n",
    "plt.title('with noise');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6c5f3c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(a1, cv2.COLOR_BGR2RGB));\n",
    "plt.title('after median filter');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb414cd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(a, cv2.COLOR_BGR2RGB));\n",
    "plt.title('original');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2785af5e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(a1, cv2.COLOR_BGR2RGB));\n",
    "plt.title('after median filter');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c926c2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Do you see how efficient this filter is in removing the “salt-and-pepper” noise? Are there any drawbacks related to this filtration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4541818",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
